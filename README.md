# ğŸ§  PaperCoder: Extract Code from Research Papers

This guide explains how to run PaperCoder using either OpenAI models (like `o3-mini`) or open-source alternatives via `vLLM`. It also covers setup, dataset details, and how to evaluate the quality of the generated repositories.

---

## ğŸ”§ Environment Setup

Install dependencies based on your use case:

```bash
# For OpenAI API
pip install openai

# For vLLM-based local inference
pip install vllm

# Optional: Install everything from a single requirements file
pip install -r requirements.txt

ğŸ“ Folder Structure (Key Outputs)

          outputs/
â”œâ”€â”€ Transformer/
â”‚   â”œâ”€â”€ analyzing_artifacts/
â”‚   â”œâ”€â”€ coding_artifacts/
â”‚   â””â”€â”€ planning_artifacts/
â””â”€â”€ Transformer_repo/   # Final code repository generated

ğŸ“„ Convert PDF to JSON (if not using LaTeX)
If your paper is in PDF format, convert it into structured JSON using s2orc-doc2json.

git clone https://github.com/allenai/s2orc-doc2json.git
cd s2orc-doc2json/grobid-0.7.3
./gradlew run

Then process your PDF:

python ../doc2json/grobid2json/process_pdf.py \
    -i <your_paper.pdf> \
    -t ../temp_dir \
    -o ../output_dir/paper_coder

ğŸš€ Run PaperCoder
Option 1: Using OpenAI API (o3-mini)
ğŸ’° Approximate cost: $0.50â€“$0.70 per paper

   export OPENAI_API_KEY="your_openai_key"

# For JSON version of the paper
cd scripts
bash run.sh

# For LaTeX source
bash run_latex.sh

Option 2: Using Open-Source Model with vLLM
Default: deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct

# For JSON paper format
cd scripts
bash run_llm.sh

# For LaTeX source
bash run_latex_llm.sh

ğŸ“š Paper2Code Dataset
PaperCoder uses the Paper2Code dataset for benchmarking.

Detailed metadata: data/paper2code/

See Section 4.1 of the official paper for more.

ğŸ§ª Evaluation: Generated Code Quality
ğŸ”¨ Setup

  pip install tiktoken
export OPENAI_API_KEY="your_openai_key"

ğŸ§¾ Reference-Free Evaluation

  cd codes/
python eval.py \
    --paper_name Transformer \
    --pdf_json_path ../examples/Transformer_cleaned.json \
    --data_dir ../data \
    --output_dir ../outputs/Transformer \
    --target_repo_dir ../outputs/Transformer_repo \
    --eval_result_dir ../results \
    --eval_type ref_free \
    --generated_n 8 \
    --papercoder

ğŸ“Œ Reference-Based Evaluation

 cd codes/
python eval.py \
    --paper_name Transformer \
    --pdf_json_path ../examples/Transformer_cleaned.json \
    --data_dir ../data \
    --output_dir ../outputs/Transformer \
    --target_repo_dir ../outputs/Transformer_repo \
    --gold_repo_dir ../examples/Transformer_gold_repo \
    --eval_result_dir ../results \
    --eval_type ref_based \
    --generated_n 8 \
    --papercoder

ğŸ“Š Example Evaluation Output

 ========================================
ğŸ“„ Paper: Transformer
ğŸ§ª Evaluation Type: ref_based
âœ… Score: 4.5
ğŸ“ˆ Valid Results: 8/8
ğŸ’µ Total Cost: ~$0.16
========================================

